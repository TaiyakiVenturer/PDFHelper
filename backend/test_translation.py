#!/usr/bin/env python3
"""
Ollamaç¿»è­¯æœå‹™æ¸¬è©¦è…³æœ¬ - æ”¯æ´è‡ªå®šç¾©TranslateHelperæ¨¡å‹
"""

import json
import time
from pathlib import Path
from services.translation_service import OllamaTranslator, GeminiTranslator

import os

instance_path = os.path.join(os.path.dirname(__file__), "instance")

def test_single_sentence():
    """æ¸¬è©¦å–®å¥ç¿»è­¯"""
    print("ğŸ”¤ æ¸¬è©¦æ¨¡å¼ 1: å–®å¥ç¿»è­¯")
    print("=" * 50)
    
    # æ¸¬è©¦ç”¨ä¾‹
    test_cases = [
        {
            "text": "Autonomous Network Optimization and Dynamic Channel Allocation for Cognitive Radio-Based Consumer IoT",
            "type": "title"
        },
        {
            "text": "The heterogeneous environment of next-generation Consumer Internet of Things (CIoT) demands efficient resource utilization and reliable network services.",
            "type": "abstract"
        },
        {
            "text": "Machine learning algorithms enable autonomous decision-making in cognitive radio networks.",
            "type": "body"
        },
        {
            "text": "Zhang, L., & Wang, H. (2023). Cognitive radio networks: A comprehensive survey. IEEE Communications Surveys & Tutorials, 25(2), 1123-1145.",
            "type": "reference"
        }
    ]
    
    try:
        translator = OllamaTranslator(
            instance_path=instance_path,
            verbose=True
        )
        
        for i, case in enumerate(test_cases, 1):
            print(f"\nğŸ“ æ¸¬è©¦æ¡ˆä¾‹ {i} ({case['type']}):")
            print(f"åŸæ–‡: {case['text']}")
            
            start_time = time.time()
            translated = translator.translate_single_text(
                text=case['text'],
                content_type=case['type']
            )
            end_time = time.time()
            
            print(f"è­¯æ–‡: {translated}")
            print(f"â±ï¸  è€—æ™‚: {end_time - start_time:.2f}ç§’")
            print("-" * 30)
        
        # é¡¯ç¤ºè¡“èªå­—å…¸
        if translator.term_dictionary:
            print(f"\nğŸ“š å»ºç«‹çš„è¡“èªå°ç…§è¡¨:")
            for en, zh in translator.term_dictionary.items():
                print(f"  {en} â†’ {zh}")
    
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")


def test_partial_content():
    """æ¸¬è©¦éƒ¨åˆ†æ–‡ä»¶ç¿»è­¯"""
    print("ğŸ“„ æ¸¬è©¦æ¨¡å¼ 2: éƒ¨åˆ†å…§å®¹ç¿»è­¯")
    print("=" * 50)
    
    # æ¨¡æ“¬content_listæ ¼å¼çš„æ¸¬è©¦æ•¸æ“š
    test_content = [
        {
            "type": "text",
            "text": "1. Introduction",
            "page_idx": 0,
            "text_level": 1
        },
        {
            "type": "text", 
            "text": "Cognitive radio (CR) technology represents a paradigm shift in wireless communications.",
            "page_idx": 0,
            "text_level": 2
        },
        {
            "type": "text",
            "text": "The Internet of Things (IoT) ecosystem requires dynamic spectrum management for optimal performance.",
            "page_idx": 0,
            "text_level": 2
        }
    ]
    
    try:
        translator = OllamaTranslator(
            instance_path=instance_path,
            verbose=True
        )
        
        print(f"ğŸ“Š æ¸¬è©¦å…§å®¹åŒ…å« {len(test_content)} å€‹æ®µè½")
        
        for i, item in enumerate(test_content):
            if item.get('type') == 'text' and item.get('text'):
                print(f"\nğŸ“ æ®µè½ {i+1}:")
                print(f"åŸæ–‡: {item['text']}")
                
                # åˆ¤æ–·å…§å®¹é¡å‹
                content_type = "title" if item.get('text_level') == 1 else "body"
                
                # æä¾›ä¸Šä¸‹æ–‡
                context = test_content[i-1]['text'] if i > 0 else ""
                
                translated = translator.translate_single_text(
                    text=item['text'],
                    content_type=content_type,
                    context=context
                )
                
                print(f"è­¯æ–‡: {translated}")
                print(f"é¡å‹: {content_type}")
                print("-" * 30)
    
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")


def test_full_document():
    """æ¸¬è©¦å®Œæ•´æ–‡ä»¶ç¿»è­¯"""
    print("ğŸ“š æ¸¬è©¦æ¨¡å¼ 3: å®Œæ•´æ–‡ä»¶ç¿»è­¯")
    print("=" * 50)
    
    # å°‹æ‰¾æ¸¬è©¦ç”¨çš„content_list.json
    content_list_path = None
    test_file_name = "SiLUæœŸæœ«å ±å‘Š"  # doc_f6a48d55
    search_paths = [
        f"instance/mineru_outputs/{test_file_name}/auto/*_content_list.json"
    ]
    
    for pattern in search_paths:
        files = list(Path(".").glob(pattern))
        if files:
            content_list_path = files[0]
            break
    
    if not content_list_path:
        print("âŒ æ‰¾ä¸åˆ°content_list.jsonæ¸¬è©¦æª”æ¡ˆ")
        print("ğŸ’¡ è«‹ç¢ºèªä»¥ä¸‹ä½ç½®æ˜¯å¦æœ‰æª”æ¡ˆ:")
        for pattern in search_paths:
            print(f"   {pattern}")
        return
    
    print(f"ğŸ“ ä½¿ç”¨æ¸¬è©¦æª”æ¡ˆ: {content_list_path}")
    

    translator = GeminiTranslator(
        instance_path=instance_path,
        verbose=True
    )
    # translator = OllamaTranslator(
    #     instance_path=instance_path,
    #     verbose=True
    # )
    
    # å…ˆè¼‰å…¥æª”æ¡ˆæŸ¥çœ‹åŸºæœ¬è³‡è¨Š
    with open(content_list_path, 'r', encoding='utf-8') as f:
        content_list = json.load(f)
    
    text_items = [item for item in content_list if item.get('type') == 'text' and item.get('text')]
    total_chars = sum(len(item['text']) for item in text_items)
    
    print(f"ğŸ“Š æ–‡ä»¶çµ±è¨ˆ:")
    print(f"   ç¸½æ®µè½æ•¸: {len(text_items)}")
    print(f"   ç¸½å­—ç¬¦æ•¸: {total_chars}")
    print(f"   é ä¼°æ™‚é–“: {len(text_items) * 3}ç§’")
    
    confirm = input("\nâ“ æ˜¯å¦ç¹¼çºŒå®Œæ•´ç¿»è­¯ï¼Ÿ(y/N): ").strip().lower()
    if confirm != 'y':
        print("â¹ï¸  å·²å–æ¶ˆå®Œæ•´ç¿»è­¯æ¸¬è©¦")
        return
    
    # åŸ·è¡Œç¿»è­¯
    start_time = time.time()
    output_path = translator.translate_content_list(
        content_list_path=str(content_list_path),
        buffer_time=1.8
    )
    end_time = time.time()
    
    print(f"\nâœ… ç¿»è­¯å®Œæˆï¼")
    print(f"ğŸ“ è¼¸å‡ºæª”æ¡ˆ: {output_path}")
    print(f"â±ï¸  ç¸½è€—æ™‚: {end_time - start_time:.1f}ç§’")
    print(f"ğŸ“š è¡“èªå°ç…§è¡¨: {len(translator.term_dictionary)} å€‹è¡“èª")


def main():
    """ä¸»æ¸¬è©¦é¸å–®"""
    print("ğŸ§ª Ollamaè‡ªå®šç¾©ç¿»è­¯æ¨¡å‹æ¸¬è©¦å·¥å…·")
    print("ä½¿ç”¨æ¨¡å‹: TranslateHelper")
    print("=" * 60)
    
    while True:
        print("\nğŸ“‹ æ¸¬è©¦é¸é …:")
        print("1. å–®å¥ç¿»è­¯æ¸¬è©¦")
        print("2. éƒ¨åˆ†å…§å®¹ç¿»è­¯æ¸¬è©¦") 
        print("3. å®Œæ•´æ–‡ä»¶ç¿»è­¯æ¸¬è©¦")
        print("4. é€€å‡º")
        
        choice = input("\nâ“ è«‹é¸æ“‡æ¸¬è©¦æ¨¡å¼ (1-4): ").strip()
        
        if choice == '1':
            test_single_sentence()
        elif choice == '2':
            test_partial_content()
        elif choice == '3':
            test_full_document()
        elif choice == '4':
            print("ğŸ‘‹ æ¸¬è©¦çµæŸ")
            break
        else:
            print("âŒ ç„¡æ•ˆé¸é …ï¼Œè«‹é‡æ–°é¸æ“‡")
        
        input("\nâ æŒ‰Enteréµç¹¼çºŒ...")


if __name__ == "__main__":
    main()
