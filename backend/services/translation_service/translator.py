"""
ç¿»è­¯å™¨åŸºé¡ - å®šç¾©ç¿»è­¯å™¨çš„åŸºæœ¬æ¥å£å’Œé€šç”¨æ–¹æ³•
"""
from typing import Optional, Dict
import json
import os
import time
import requests
from pathlib import Path

from backend.services.llm_service import BaseLLMService
from backend.api import ProgressManager

import logging
from backend.api import setup_project_logger  # å°å…¥æ—¥èªŒè¨­ç½®å‡½æ•¸

setup_project_logger(verbose=True)  # è¨­ç½®å…¨å±€æ—¥èªŒè¨˜éŒ„å™¨
logger = logging.getLogger(__name__)

class Translator():
    """
    ### é€šç”¨ç¿»è­¯å™¨

    ä½¿ç”¨æŒ‡å®šçš„LLMæœå‹™é€²è¡Œæ–‡æœ¬ç¿»è­¯ã€‚
    """
    def __init__(self, instance_path: str, llm_service_obj: BaseLLMService, verbose: bool = False):
        """
        åˆå§‹åŒ–ç¿»è­¯å™¨

        Args:
            instance_path: å­˜æ”¾PDFçš„è³‡æ–™å¤¾è·¯å¾‘
            llm_services_obj: LLMæœå‹™å¯¦ä¾‹
            verbose: æ˜¯å¦å•Ÿç”¨è©³ç´°æ¨¡å¼
        """
        self.llm_service = llm_service_obj

        self.verbose = verbose
        self.term_dictionary = {}

        self.instance_path = instance_path
        self.progress_path = os.path.join(instance_path, "translated_files", "unfinished_file")

        self.is_reference = False

    def is_available(self) -> bool:
        """æª¢æŸ¥ç¿»è­¯å™¨æ˜¯å¦å¯ç”¨"""
        return self.llm_service.is_available()

    def _get_system_prompt(self) -> str:
        """ç²å–ç³»çµ±æç¤ºè©"""
        return """
ä½ æ˜¯å°ˆæ¥­çš„å­¸è¡“è«–æ–‡ç¿»è­¯å°ˆå®¶ï¼Œå°ˆç²¾æ–¼è‹±æ–‡å­¸è¡“æ–‡ç»çš„ç¹é«”ä¸­æ–‡ç¿»è­¯ã€‚

## ç¿»è­¯åŸå‰‡èˆ‡åˆ†é¡è™•ç†
### å…§å®¹é¡å‹ï¼š
- **æ¨™é¡Œ (title)**: ç°¡æ½”æº–ç¢ºï¼Œçªå‡ºç ”ç©¶æ ¸å¿ƒï¼Œé¿å…å†—é•·è¡¨é”
- **æ‘˜è¦ (abstract)**: ä¿æŒé‚è¼¯å®Œæ•´æ€§ï¼Œç¶­æŒå­¸è¡“åš´è¬¹æ€§å’Œçµæ§‹å±¤æ¬¡
- **æ­£æ–‡ (body)**: é‚è¼¯æ¸…æ™°ï¼Œè¡“èªæº–ç¢ºï¼Œè¡¨é”è‡ªç„¶æµæš¢
- **åƒè€ƒæ–‡ç» (reference)**: ä¿æŒæ ¼å¼ï¼Œåƒ…éœ€ç¿»è­¯è«–æ–‡æ¨™é¡Œ

### å°ˆæ¥­è¡“èªèˆ‡æ ¼å¼è¦æ±‚ï¼š
1. **è¡“èªä¸€è‡´æ€§**ï¼šå»ºç«‹è¡“èªå°ç…§ï¼Œç¢ºä¿å…¨æ–‡çµ±ä¸€ç¿»è­¯
2. **é¦–æ¬¡è¡“èª**ï¼šä¸­æ–‡ç¿»è­¯ï¼ˆè‹±æ–‡åŸæ–‡ï¼‰ï¼Œå¦‚ï¼šèªçŸ¥ç„¡ç·šé›» (Cognitive Radio)
3. **ä¿æŒåŸæ–‡**ï¼šæ•¸å­¸å…¬å¼ã€è®Šæ•¸åã€ç¬¦è™Ÿã€å…¬èªç¸®å¯« (AIã€IoTã€5Gç­‰)

### ç¿»è­¯å“è³ªæ§åˆ¶ï¼š
- å„ªå…ˆæ„è­¯ç¢ºä¿èªç¾©å®Œæ•´ï¼Œé¿å…ç”Ÿç¡¬ç›´è­¯
- ç¶­æŒåŸæ–‡é‚è¼¯å±¤æ¬¡å’Œæ®µè½çµæ§‹
- ç¢ºä¿ä¸­æ–‡è¡¨é”ç¬¦åˆå­¸è¡“å¯«ä½œç¿’æ…£
- ä¿æŒå°ˆæ¥­æ€§èˆ‡å¯è®€æ€§çš„å¹³è¡¡

### è™•ç†æ ¼å¼ï¼š
ä¸Šä¸‹æ–‡ï¼š{context}
å…§å®¹é¡å‹ï¼š{content_type}
ç¿»è­¯å…§å®¹ï¼š{text}  
ç¿»è­¯è¼¸å‡ºï¼š{respond}

**é‡è¦ï¼šåƒ…è¼¸å‡ºç¿»è­¯çµæœï¼Œç„¡éœ€é¡å¤–èªªæ˜ï¼›ä¸Šä¸‹æ–‡åƒ…ä¾›åƒè€ƒï¼Œè«‹å‹¿å°‡ä¸Šä¸‹æ–‡å…§å®¹è¤‡è£½åˆ°å›ç­”ä¸­**
"""

    def send_translate_request(self, prompt: str, end_chat: bool) -> str:
        """ç™¼é€ç¿»è­¯è«‹æ±‚çµ¦ç¿»è­¯å™¨"""
        return self.llm_service.send_multi_request(
            prompt, 
            self._get_system_prompt(), 
            end_chat=end_chat
        )
    
    def _get_term_dictionary(self) -> dict:
        """
        ç²å–è¡“èªå°ç…§è¡¨
        """
        return self.term_dictionary

    def _set_term_dictionary(self, term_dictionary: dict):
        """
        è¨­ç½®è¡“èªå°ç…§è¡¨
        """
        self.term_dictionary = term_dictionary

    def _get_relevant_terms(self, text: str) -> str:
        """ç²å–ç›¸é—œçš„å·²ç¿»è­¯è¡“èª"""
        if not self.term_dictionary:
            return ""
            
        relevant = []
        for en_term, zh_term in self.term_dictionary.items():
            if en_term.lower() in text.lower():
                relevant.append(f"{en_term}â†’{zh_term}")

        return "; ".join(relevant[:5])  # é™åˆ¶æœ€å¤š5å€‹è¡“èª
    
    def _update_term_dictionary(self, original: str, translated: str):
        """æ›´æ–°è¡“èªå°ç…§è¡¨"""
        # ç°¡å–®çš„è¡“èªæå–é‚è¼¯ï¼ˆå¯ä»¥å¾ŒçºŒæ”¹é€²ï¼‰
        if len(original.split()) <= 3 and len(translated) <= 20:
            # çŸ­èªå¯èƒ½æ˜¯è¡“èª
            self.term_dictionary[original.strip()] = translated.strip()

    def _clean_translation(self, text: str) -> str:
        """æ¸…ç†ç¿»è­¯çµæœ (æš«æ™‚ä¸å•Ÿç”¨)"""
        if not text:
            return ""
            
        # ç§»é™¤å¯èƒ½çš„å‰ç¶´èªªæ˜
        prefixes_to_remove = [
            "ç¿»è­¯çµæœï¼š", "ç¿»è­¯ï¼š", "ä¸­æ–‡ç¿»è­¯ï¼š", "è­¯æ–‡ï¼š", "ç¹é«”ä¸­æ–‡ï¼š",
            "ç¿»è­¯å¦‚ä¸‹ï¼š", "ä»¥ä¸‹æ˜¯ç¿»è­¯ï¼š", "Translation:", "Chinese:"
        ]
        
        for prefix in prefixes_to_remove:
            if text.startswith(prefix):
                text = text[len(prefix):].strip()
                
        # ç§»é™¤å¤šé¤˜çš„å¼•è™Ÿ
        text = text.strip('"\'')
        
        # æ¨™æº–åŒ–ç©ºæ ¼
        text = " ".join(text.split())
        
        return text

    def _build_modelfile_prompt(self, text: str, content_type: str) -> str:
        """æ§‹å»ºé…åˆmodelfileçš„ç°¡æ½”æç¤ºè©"""
        # æª¢æŸ¥æ˜¯å¦æœ‰ç›¸é—œè¡“èªéœ€è¦ä¿æŒä¸€è‡´æ€§
        relevant_terms = self._get_relevant_terms(text)
        terms_context = ""
        if relevant_terms:
            terms_context = f"\nå·²å»ºç«‹è¡“èªå°ç…§: {relevant_terms}"
        
        # æ ¹æ“šmodelfileæ ¼å¼æ§‹å»ºç°¡æ½”prompt
        prompt = f"""å…§å®¹é¡å‹ï¼š{content_type}; ç¿»è­¯å…§å®¹ï¼š{text}; è¡“èªå°ç…§è¡¨ï¼š{terms_context}ç¿»è­¯è¼¸å‡ºï¼š"""

        return prompt

    def translate_single_text(self, text: str, content_type: str = "body", max_retries: int = 3) -> str:
        """
        ç¿»è­¯å–®ä¸€æ®µè½æ–‡å­—ã€‚
        
        Args:
            text: è¦ç¿»è­¯çš„æ–‡æœ¬
            content_type: å…§å®¹é¡å‹ (title/abstract/body/reference)
            max_retries: æœ€å¤§é‡è©¦æ¬¡æ•¸
            
        Returns:
            ç¿»è­¯å¾Œçš„æ–‡æœ¬ (å¦‚æœå‡ºç¾éŒ¯èª¤ï¼Œè¿”å›ç©ºå­—ä¸²)
        """
        prompt = self._build_modelfile_prompt(text, content_type)

        for attempt in range(1, max_retries + 1):
            try:
                translation = self.send_translate_request(prompt, end_chat=False)
                if not translation:
                    logger.warning(f"ç¿»è­¯å‡ºç¾éŒ¯èª¤ï¼Œé‡æ–°å˜—è©¦ (å˜—è©¦ {attempt}/{max_retries})")
                    continue

                # æ›´æ–°è¡“èªå°ç…§è¡¨
                self._update_term_dictionary(text, translation)
                
                return translation
            
            except requests.exceptions.Timeout:
                logger.warning(f"ç¿»è­¯è¶…æ™‚ (å˜—è©¦ {attempt}/{max_retries})")
                if attempt < max_retries:
                    time.sleep(2)
                    continue
                else:
                    return ""
            except requests.exceptions.RequestException as e:
                logger.error(f"è«‹æ±‚éŒ¯èª¤ (å˜—è©¦ {attempt}/{max_retries}): {e}")
                if attempt < max_retries:
                    wait_time = 2 ** attempt
                    logger.info(f"ç­‰å¾… {wait_time} ç§’å¾Œé‡è©¦...")
                    time.sleep(wait_time)
                else:
                    logger.error("å·²é”åˆ°æœ€å¤§é‡è©¦æ¬¡æ•¸ï¼Œæ”¾æ£„ç¿»è­¯è©²æ®µè½")
                    return ""
            except Exception as e:
                logger.error(f"ç¿»è­¯éŒ¯èª¤ (å˜—è©¦ {attempt}/{max_retries}): {e}")
                if attempt < max_retries:
                    wait_time = 2 ** attempt
                    logger.info(f"ç­‰å¾… {wait_time} ç§’å¾Œé‡è©¦...")
                    time.sleep(wait_time)
                else:
                    logger.error("å·²é”åˆ°æœ€å¤§é‡è©¦æ¬¡æ•¸ï¼Œæ”¾æ£„ç¿»è­¯è©²æ®µè½")
                    return ""
        if self.verbose:
            logger.info("è¶…éæœ€å¤§é‡è©¦æ¬¡æ•¸")
        return ""

    def translate_content_list(self, 
            content_list_path: str, 
            buffer_time: float = 0.5
        ) -> str:
        """
        ç¿»è­¯content_list.jsonæª”æ¡ˆ
        
        Args:
            content_list_path: content_list.jsonæª”æ¡ˆè·¯å¾‘
            buffer_time: æ¯æ¬¡è«‹æ±‚å¾Œçš„ç·©è¡æ™‚é–“ï¼Œé¿å…éæ–¼é »ç¹è«‹æ±‚
            
        Returns:
            ç¿»è­¯çµæœæª”æ¡ˆè·¯å¾‘
        """
        # è¼‰å…¥content_list.json
        content_list_path = Path(content_list_path)
        if not content_list_path.exists():
            raise FileNotFoundError(f"æª”æ¡ˆä¸å­˜åœ¨: {content_list_path}")

        file_name = '_'.join(str(content_list_path.stem).split("_")[:-2])
        progress_path = os.path.join(self.progress_path, f"{file_name}_progress.json")
        if os.path.exists(progress_path):
            # è¼‰å…¥é€²åº¦æª”æ¡ˆ
            with open(progress_path, 'r', encoding='utf-8') as f:
                progress_data = json.load(f)
            content_list = progress_data.get("content_list", [])

            if self.verbose:
                logger.info(f"åµæ¸¬åˆ°ç¿»è­¯é€²åº¦: {progress_path}")
                logger.info(f"é‡æ–°è¼‰å…¥ç¿»è­¯é€²åº¦: å‰©é¤˜ {self._check_translated_progress(content_list)} å€‹æ®µè½")

            self._set_term_dictionary(progress_data.get("term_dictionary", {}))

            if self._check_translated_progress(content_list) == 0:
                logger.info("æª”æ¡ˆå·²å…¨éƒ¨ç¿»è­¯å®Œæˆï¼Œç„¡éœ€é‡è¤‡ç¿»è­¯")
                return self._save_translated_progress(content_list, file_name)
        else:
            # åˆæ¬¡ç¿»è­¯ï¼Œè¼‰å…¥åŸå§‹æª”æ¡ˆ
            with open(content_list_path, 'r', encoding='utf-8') as f:
                content_list = json.load(f)

            # ä¿å­˜åˆå§‹é€²åº¦ï¼Œå†è¼‰å…¥é€²åº¦æª”æ¡ˆ
            self._save_translated_progress(content_list, file_name)
            with open(progress_path, 'r', encoding='utf-8') as f:
                progress_data = json.load(f)
            content_list = progress_data.get("content_list", [])

            if self.verbose:
                logger.info(f"åˆæ¬¡ç¿»è­¯ï¼Œå»ºç«‹é€²åº¦æª”æ¡ˆ: {progress_path}")
                logger.info(f"ç¸½è¨ˆç¿»è­¯é …ç›®: {len(content_list)} å€‹é …ç›®")

        # ç¿»è­¯è™•ç†
        translated_count = 0

        last_progress = 30  # åˆå§‹é€²åº¦
        per_progress = 37 / len(content_list)  # 37%åˆ†é…çµ¦ç¿»è­¯
        for index, item in enumerate(content_list):
            ProgressManager.progress_update(last_progress + per_progress * index, f"ç¿»è­¯ä¸­: æ­£åœ¨ç¿»è­¯ç¬¬ {index+1}/{len(content_list)} å€‹æ®µè½", "translating-json")
            if item.get('translation_metadata', {}) != {}:
                continue
            if not (item.get('type') == 'text' and item.get('text')):
                continue

            if translated_count != 0 and translated_count % 10 == 0:
                start_time = time.time()
                logger.info(f"ç¬¬ {index//10} å€‹æª¢æŸ¥é»ï¼Œæ­£åœ¨ä¿å­˜ç¿»è­¯é€²åº¦...")
                ProgressManager.progress_update(last_progress + per_progress * index, f"å„²å­˜ä¸­: æ­£åœ¨ä¿å­˜ç¿»è­¯é€²åº¦...", "translating-json")
                self._save_translated_progress(content_list, file_name)
                end_time = time.time()

                batch_sleep = buffer_time*5 - (end_time - start_time)
                if batch_sleep > 0:
                    time.sleep(batch_sleep)
            
            # åˆ¤æ–·å…§å®¹é¡å‹
            content_type = self._classify_content_type(item)

            # ç¿»è­¯æ–‡æœ¬
            original_text = item['text']
            translated_text = self.translate_single_text(
                text=original_text,
                content_type=content_type
            )
            if translated_text == "":
                logger.error(f"ç¿»è­¯å¤±æ•—ï¼Œè·³éæ®µè½: {original_text}")
                continue
            else:
                if self.verbose:
                    logger.info(f"ç¿»è­¯é€²åº¦: {index+1}/{len(content_list)} - ç¬¬{item.get('page_idx', 0)+1}é ")

            translated_count += 1

            # ä¿å­˜ç¿»è­¯çµæœ
            item['text_en'] = original_text
            item['text_zh'] = translated_text
            item['translation_metadata'] = {
                'model': self.llm_service.model_name,
                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
                'content_type': content_type
            }
            
            if self.verbose:
                logger.info(f"   åŸæ–‡: {original_text[:50]}...")
                logger.info(f"   è­¯æ–‡: {translated_text[:50]}...")
                logger.info("")

            # é¿å…è«‹æ±‚éæ–¼é »ç¹
            time.sleep(buffer_time)

        # çµæŸå¤šè¼ªå°è©±
        self.send_translate_request("", end_chat=True)

        # ç¿»è­¯çµæŸå¾Œï¼Œçµ±ä¸€ç§»é™¤åŸå§‹æ–‡æœ¬
        for item in content_list:
            item.pop('text', None)

        # ä¿å­˜ç¿»è­¯çµæœ
        output_path = os.path.join(os.path.dirname(self.progress_path), f"{file_name}_translated.json")
        
        # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(content_list, f, ensure_ascii=False, indent=2)

        logger.info("ç¿»è­¯å®Œæˆï¼")
        logger.info(f"ç¿»è­¯çµæœå·²ä¿å­˜: {output_path}")
        logger.info(f"å…±ç¿»è­¯ {translated_count} å€‹æ®µè½")

        self._clear_translated_progress(file_name)
        
        return str(output_path)

    def _classify_content_type(self, item: Dict) -> str:
        """åˆ†é¡å…§å®¹é¡å‹"""
        text = item.get('text', '').lower()
        text_level = item.get('text_level')
        
        # æ‘˜è¦åˆ¤æ–·
        if 'abstract' in text:
            return 'abstract'

        # åƒè€ƒæ–‡ç»å€åŸŸåˆ¤æ–·
        if 'reference' in text:
            self.is_reference = True

        # åƒè€ƒæ–‡ç»åˆ¤æ–·
        if self.is_reference and any(ref in text for ref in ['[', 'doi:', 'http://', 'https://', '@']):
            return 'reference'
        
        # æ¨™é¡Œåˆ¤æ–·
        if text_level == 1:
            return 'title'
        
        # é»˜èªç‚ºæ­£æ–‡
        return 'body'

    def _save_translated_progress(self, progress_data: list, file_name: str) -> str:
        """
        ä¿å­˜ç¿»è­¯é€²åº¦åˆ°æœ¬åœ°æ–‡ä»¶
        
        Args:
            progress_data: åŒ…å«ç¿»è­¯é€²åº¦çš„listæ•¸æ“š
            file_name: è¼¸å‡ºæª”æ¡ˆåç¨±

        Returns:
            str: è¼¸å‡ºæª”æ¡ˆçš„è·¯å¾‘
        """
        output_path = os.path.join(self.progress_path, f"{file_name}_progress.json")

        # ç¢ºä¿é€²åº¦ç›®éŒ„å­˜åœ¨
        os.makedirs(self.progress_path, exist_ok=True)

        # ğŸ”§ ä¿®æ­£ï¼šå‰µå»ºåŒ…å«é€²åº¦ä¿¡æ¯çš„æ–°çµæ§‹ï¼Œä¸ä¿®æ”¹åŸå§‹æ•¸æ“š
        progress_info = {
            "content_list": progress_data,  # åŸå§‹ç¿»è­¯æ•¸æ“š
            "save_time": time.strftime('%Y-%m-%d %H:%M:%S'),
            "term_dictionary": self.term_dictionary.copy(),  # å‰µå»ºå‰¯æœ¬
            "translator_type": self.llm_service.model_name
        }

        try:
            with open(output_path, "w", encoding="utf-8") as f:
                json.dump(progress_info, f, ensure_ascii=False, indent=2)
            return output_path
        except Exception as e:
            logger.error(f"ä¿å­˜ç¿»è­¯é€²åº¦æ™‚å‡ºéŒ¯: {e}")
            return ""

    def _load_translated_progress(self, file_name: str) -> Optional[dict]:
        """
        å¾æœ¬åœ°æ–‡ä»¶åŠ è¼‰ç¿»è­¯é€²åº¦

        Args:
            file_name: åŸå§‹æ–‡ä»¶å

        Returns:
            åŒ…å«ç¿»è­¯é€²åº¦çš„å­—å…¸æ•¸æ“šï¼Œæˆ–Noneå¦‚æœåŠ è¼‰å¤±æ•—
        """
        input_path = os.path.join(self.progress_path, f"{file_name}_progress.json")

        try:
            with open(input_path, "r", encoding="utf-8") as f:
                progress_info = json.load(f)
            return progress_info
        except Exception as e:
            logger.error(f"åŠ è¼‰ç¿»è­¯é€²åº¦æ™‚å‡ºéŒ¯: {e}")
            return None

    def _check_translated_progress(self, content_list: list) -> int:
        """
        æª¢æŸ¥ç¿»è­¯é€²åº¦

        Args:
            content_list: åŸå§‹å…§å®¹åˆ—è¡¨

        Returns:
            ç¿»è­¯ç¼ºå¤±æ•¸é‡
        """

        unfinished_count = 0
        for item in content_list:
            if item.get('type') != 'text':
                continue
            if item.get('text') == "":
                continue
            if item.get("translation_metadata") is None:
                unfinished_count += 1
        return unfinished_count

    def _clear_translated_progress(self, file_name: str) -> bool:
        """
        æ¸…é™¤ç¿»è­¯é€²åº¦æª”æ¡ˆ

        Args:
            file_name: åŸå§‹æ–‡ä»¶å

        Returns:
            æ˜¯å¦æˆåŠŸæ¸…é™¤ç¿»è­¯é€²åº¦
        """
        progress_path = os.path.join(self.progress_path, f"{file_name}_progress.json")

        try:
            if os.path.exists(progress_path):
                os.remove(progress_path)
                logger.info(f"æˆåŠŸæ¸…é™¤ç¿»è­¯é€²åº¦æª”æ¡ˆ: {progress_path}")
            else:
                logger.warning(f"ç¿»è­¯é€²åº¦æª”æ¡ˆä¸å­˜åœ¨: {progress_path}")
            return True
        except Exception as e:
            logger.error(f"æ¸…é™¤ç¿»è­¯é€²åº¦æ™‚å‡ºéŒ¯: {e}")
            return False